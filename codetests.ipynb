{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyYaml\n",
      "  Obtaining dependency information for PyYaml from https://files.pythonhosted.org/packages/bc/06/1b305bf6aa704343be85444c9d011f626c763abb40c0edc1cad13bfd7f86/PyYAML-6.0.1-cp312-cp312-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading PyYAML-6.0.1-cp312-cp312-macosx_10_9_x86_64.whl.metadata (2.1 kB)\n",
      "Downloading PyYAML-6.0.1-cp312-cp312-macosx_10_9_x86_64.whl (178 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: PyYaml\n",
      "Successfully installed PyYaml-6.0.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.12 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyYaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'connector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 32\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m table_names\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m#Get table names from the db\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m table_names \u001b[38;5;241m=\u001b[39m \u001b[43mconnector\u001b[49m\u001b[38;5;241m.\u001b[39mlist_db_tables(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/itsanya/AiCore/MRDC/db_creds.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(table_names)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'connector' is not defined"
     ]
    }
   ],
   "source": [
    "#Connect with and upload data to the database\n",
    "import yaml\n",
    "from sqlalchemy import create_engine, inspect\n",
    "\n",
    "class DatabaseConnector:\n",
    "#initialize the db engine (makes connecting to other classes smoother)\n",
    "    def __init__(self, creds_path):\n",
    "        self.creds_path = creds_path\n",
    "        self.engine = self.init_db_engine()\n",
    "\n",
    "#Create a method read_db_creds this will read the credentials yaml file and return a dictionary of the credentials.\n",
    "    def read_db_creds(self):\n",
    "        with open(self.creds_path, 'r') as creds:\n",
    "            credentials = yaml.safe_load(creds)\n",
    "        return dict(credentials)\n",
    "\n",
    "#read the credentials from the return of read_db_creds and initialise and return an sqlalchemy database engine\n",
    "    def init_db_engine(self):\n",
    "        credentials = self.read_db_creds()\n",
    "        db_url = f\"postgresql://{credentials['RDS_USER']}:{credentials['RDS_PASSWORD']}@{credentials['RDS_HOST']}:{credentials['RDS_PORT']}/{credentials['RDS_DATABASE']}\"\n",
    "        engine = create_engine(db_url)\n",
    "        return engine\n",
    "\n",
    "#Using the engine from init_db_engine create a method list_db_tables to list all the tables in the database so you know which tables you can extract data from.\n",
    "    def list_db_tables(self):\n",
    "        inspector = inspect(self.engine)\n",
    "        table_names = inspector.get_table_names()\n",
    "        return table_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This class will work as a utility class, in it you will be creating methods that help extract data from different data sources.\n",
    "#The methods contained will be fit to extract data from a particular data source, these sources will include CSV files, an API and an S3 bucket.\n",
    "import pandas as pd\n",
    "from database_utils import DatabaseConnector\n",
    "\n",
    "class DataExtractor:\n",
    "#Initialize an instance via DatabaseConnector:\n",
    "    def __init__(self):\n",
    "        self.connector_instance = DatabaseConnector('/Users/itsanya/AiCore/MRDC/db_creds.yaml')\n",
    "\n",
    "#Take in an instance of your DatabaseConnector class and the table name as an argument and return a pandas DataFrame\n",
    "    def read_rds_table(self, table_name):\n",
    "        engine = self.connector_instance.engine\n",
    "        query = f\"SELECT * FROM {table_name}\"\n",
    "        df = pd.read_sql(query, engine)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['legacy_store_details', 'legacy_users', 'orders_table']\n"
     ]
    }
   ],
   "source": [
    "#Get table names from the db\n",
    "creds_path = '/Users/itsanya/AiCore/MRDC/db_creds.yaml'\n",
    "connector = DatabaseConnector(creds_path)\n",
    "table_names = connector.list_db_tables()\n",
    "print(table_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCleaning:\n",
    "#Initialize:\n",
    "    def __init__ ():\n",
    "\n",
    "#Clean the user data, look out for NULL values, errors with dates, incorrectly typed values and rows filled with the wrong information\n",
    "#Handling NULL values: Replace NULLs with a default value, impute using statistics, or drop rows/columns with too many missing values.\n",
    "#Correcting date errors: Standardize date formats, parse and fill missing or incorrect dates.\n",
    "#Correcting incorrectly typed values: Convert data types to the appropriate format (e.g., dates to datetime objects, strings to numeric values).\n",
    "#Handling rows with wrong information: Identify outliers or incorrect entries and remove or correct them.\n",
    "    def clean_user_data(self):\n",
    "        \n",
    "\n",
    "#This method will take in a Pandas DataFrame and table name to upload to as an argument.\n",
    "    def upload_to_db():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Once extracted and cleaned use the upload_to_db method to store the data in your sales_data database in a table named dim_users."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
